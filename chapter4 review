## 4.6 íšŒê·€ì§„ë‹¨

- ì„¤ëª…ì„ ìœ„í•œ ëª¨ë¸ë§(ì—°êµ¬ëª©ì )ì—ì„œëŠ” ë§¤ ë‹¨ê³„ë§ˆë‹¤ ì•ì„œ ì„¤ëª…í•œ ì—¬ëŸ¬ ì¸¡ì •ì§€í‘œë“¤ì„ ê³ ë ¤í•˜ì—¬, ë§¤ ë‹¨ê³„ë§ˆë‹¤ ëª¨ë¸ì´ ë°ì´í„°ì— ì–¼ë§ˆë‚˜ ì í•©í•œì§€ë¥¼ í‰ê°€í•œë‹¤. ëŒ€ë¶€ë¶„ì€ ì”ì°¨ë¶„ì„ì„ ê¸°ë³¸ìœ¼ë¡œ í•œë‹¤. ì´ëŸ° ë‹¨ê³„ë“¤ì€ ì§ì ‘ì ìœ¼ë¡œ ì˜ˆì¸¡ì •í™•ë„ë¥¼ ë‹¤ë£¨ëŠ” ê²ƒì€ ì•„ë‹ˆì§€ë§Œ, ì˜ˆì¸¡ ì„¤ì •ì— ì¤‘ìš”í•œ í†µì°°ì„ ì¤„ ìˆ˜ ìˆë‹¤.

<aside>
ğŸ’¡ ìš©ì–´ì •ë¦¬
1. í‘œì¤€í™” ì”ì°¨ : ì”ì°¨ë¥¼ í‘œì¤€í¸ì°¨ë¡œ ë‚˜ëˆˆ ê°’
2. íŠ¹ì‡ê°’ : ë‚˜ë¨¸ì§€ë°ì´í„°ì™€ ë©€ë¦¬ ë–¨ì–´ì§„ ë ˆì½”ë“œ, í˜¹ì€ ì˜ˆì¸¡ê°’ê³¼ ë©€ë¦¬ ë–¨ì–´ì§„ ì‹¤ì œ ê°’
3. ì˜í–¥ê°’ : ìˆì„ ë•Œì™€ ì—†ì„ ë•Œ íšŒê·€ë°©ì •ì‹ì´ í° ì°¨ì´ë¥¼ ë³´ì´ëŠ” ê°’ í˜¹ì€ ë ˆì½”ë“œ
4. ë ˆë²„ë¦¬ì§€ : íšŒê·€ì‹ì— í•œ ë ˆì½”ë“œê°€ ë¯¸ì¹˜ëŠ” ì˜í–¥ë ¥ì˜ ì •ë„
5. ë¹„ì •ê·œ ì”ì°¨ : ì •ê·œë¶„í¬ë¥¼ ë”°ë¥´ì§€ ì•ŠëŠ” ì”ì°¨. íšŒê·€ë¶„ì„ì˜ ìš”ê±´ì„ ë¬´íš¨ë¡œ ë§Œë“¤ ìˆ˜ ìˆìŒ
6. ì´ë¶„ì‚°ì„± : ì–´ë–¤ ë²”ìœ„ ë‚´ ì”ì°¨ê°€ ë§¤ìš° ë†’ì€ ë¶„ì‚°ì„ ë³´ì´ëŠ” ê²½í–¥ 
7. í¸ì”ì°¨ê·¸ë¦¼ : ê²°ê³¼ë³€ìˆ˜ì™€ íŠ¹ì • ì˜ˆì¸¡ë³€ìˆ˜ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ ì§„ë‹¨í•˜ëŠ” ê·¸ë¦¼

</aside>

## 4.6.1 íŠ¹ì‡ê°’

- íšŒê·€ì—ì„œ íŠ¹ì‡ê°’ì€ ì‹¤ì œ yê°’ì´ ì˜ˆì¸¡ëœ ê°’ì—ì„œ ë©€ë¦¬ ë–¨ì–´ì ¸ìˆëŠ” ê²½ìš°ë¥¼ ë§í•œë‹¤.
- ì”ì°¨ë¥¼ í‘œì¤€í¸ì°¨ë¡œ ë‚˜ëˆˆ ê°’ì„ í‘œì¤€í™” ì”ì°¨ë¼ê³  í•˜ëŠ”ë°, ì´ ê°’ì„ ì¡°ì‚¬í•´ì„œ íŠ¹ì‡ê°’ì„ ë°œê²¬í•  ìˆ˜ ìˆë‹¤.
- í‘œì¤€í™” ì”ì°¨ëŠ” â€˜íšŒê·€ì„ ìœ¼ë¡œ ë¶€í„° ë–¨ì–´ì§„ ì •ë„ë¥¼ í‘œì¤€í¸ì°¨ ê°œìˆ˜ë¡œ í‘œí˜„í•œ ê°’â€™ì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤.

ì˜ˆì œ )í‚¹ì¹´ìš´í‹° ì£¼íƒë§¤ë§¤ë°ì´í„°ì—ì„œ ìš°í¸ë²ˆí˜¸ê°€ 98105ì¸ ì§€ì—­ì˜ ë°ì´í„°ë¡œ íšŒê·€ëª¨í˜• êµ¬í•˜ê¸°

```python
house_98105 = house.loc[house['ZipCode'] == 98105, ]

predictors = ['SqFtTotLiving', 'SqFtLot', 'Bathrooms', 'Bedrooms',
              'BldgGrade']
outcome = 'AdjSalePrice'

house_outlier = sm.OLS(house_98105[outcome], house_98105[predictors].assign(const=1))
result_98105 = house_outlier.fit()
print(result_98105.summary())

//ê²°ê³¼
OLS Regression Results                            
==============================================================================
Dep. Variable:           AdjSalePrice   R-squared:                       0.795
Model:                            OLS   Adj. R-squared:                  0.792
Method:                 Least Squares   F-statistic:                     238.7
Date:                Sun, 31 Jul 2022   Prob (F-statistic):          1.69e-103
Time:                        15:37:31   Log-Likelihood:                -4226.0
No. Observations:                 313   AIC:                             8464.
Df Residuals:                     307   BIC:                             8486.
Df Model:                           5                                         
Covariance Type:            nonrobust                                         
=================================================================================
                    coef    std err          t      P>|t|      [0.025      0.975]
---------------------------------------------------------------------------------
SqFtTotLiving   209.6023     24.408      8.587      0.000     161.574     257.631
SqFtLot          38.9333      5.330      7.305      0.000      28.445      49.421
Bathrooms      2282.2641      2e+04      0.114      0.909    -3.7e+04    4.16e+04
Bedrooms      -2.632e+04   1.29e+04     -2.043      0.042   -5.17e+04    -973.867
BldgGrade        1.3e+05   1.52e+04      8.533      0.000       1e+05     1.6e+05
const         -7.725e+05   9.83e+04     -7.861      0.000   -9.66e+05   -5.79e+05
==============================================================================
Omnibus:                       82.127   Durbin-Watson:                   1.508
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              586.561
Skew:                           0.859   Prob(JB):                    4.26e-128
Kurtosis:                       9.483   Cond. No.                     5.63e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 5.63e+04. This might indicate that there are
strong multicollinearity or other numerical problems.
```

- í‘œì¤€í™” ì”ì°¨êµ¬í•˜ê³  ê°€ì¥ì‘ì€ í‘œì¤€í™” ì”ì°¨ ìœ„ì¹˜ êµ¬í•˜ê¸°
    - ê²°ê³¼ë¥¼ ë³´ë©´ í‘œì¤€í¸ì°¨ì˜ 4ë°°ì´ìƒì´ë‚˜ íšŒê·€ì‹ê³¼ ì°¨ì´ë¥¼ ë³´ì´ëŠ”ë° ì´ì— í•´ë‹¹í•˜ëŠ” ì¶”ì •ì¹˜ëŠ” 757,754ë‹¬ëŸ¬ë‹¤.
        
        ```python
        influence = OLSInfluence(result_98105)
        sresiduals = influence.resid_studentized_internal
        
        print(sresiduals.idxmin(), sresiduals.min())
        
        //ê²°ê³¼
        24333 -4.326731804078567
        ```
        
- íŠ¹ì‡ê°’ì— í•´ë‹¹í•˜ëŠ” ë ˆì½”ë“œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤
    - ì´ê²½ìš° ë ˆì½”ë“œê°€ ë­”ê°€ ì˜ëª»ë¬ë‹¤ëŠ”ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ì´ ìš°í¸ë²ˆí˜¸ì— í•´ë‹¹í•˜ëŠ” ì§€ì—­ì—ì„œ ì´ì •ë„ í‰ìˆ˜ë¼ë©´ 119,748ë‹¬ëŸ¬ë³´ë‹¤ëŠ” ë” ë¹„ì‹¸ì•¼ ì •ìƒì´ë‹¤.
    - ì´ëŸ°ê²½ìš°ëŠ” íšŒê·€ì— í¬í•¨ë˜ë©´ ì•ˆëœë‹¤.
    
    ```python
    outlier = house_98105.loc[sresiduals.idxmin(), :]
    print('AdjSalePrice', outlier[outcome])
    print(outlier[predictors])
    
    //ê²°ê³¼
    AdjSalePrice 119748.0
    SqFtTotLiving    2900
    SqFtLot          7276
    Bathrooms           3
    Bedrooms            6
    BldgGrade           7
    Name: 24333, dtype: object
    ```
    

## 4.6.2 ì˜í–¥ê°’

- íšŒê·€ëª¨í˜•ì—ì„œ ì œì™¸ë¬ì„ ë•Œ ëª¨ë¸ì— ì¤‘ìš”í•œ ë³€í™”ë¥¼ ê°€ì ¸ì˜¤ëŠ” ê°’ì„ ì£¼ì˜í–¥ê´€ì¸¡ê°’ì´ë¼ê³  í•œë‹¤. íšŒê·€ ë¶„ì„ì—ì„œ ì”ì°¨ê°€ í¬ë‹¤ê³  ëª¨ë‘ ì´ëŸ°ê°’ì´ ë˜ëŠ”ê²ƒì€ ì•„ë‹ˆë‹¤.
    - ì˜¤ë¥¸ìª½ ë§¨ìœ„ ê°’ì„ ë°˜ì˜í–ˆì„ë•Œì˜ ì„ ì€ íŒŒë€ìƒ‰, ì œê±°í–ˆì„ë•Œ ì„ ì€ ì£¼í™©ìƒ‰ ì ì„ ì´ë‹¤. ì´ ë°ì´í„°ê°’ì€ íšŒê·€ ê²°ê³¼ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ì§€ë§Œ. ì›ë˜ íšŒê·€ì—ì„œ í° íŠ¹ì´ê°’ìœ¼ë¡œ ë‚˜íƒ€ë‚œ ê²ƒì€ ì•„ë‹ˆë‹¤. ì´ ë°ì´í„° ê°’ì€ íšŒê·€ì— ëŒ€í•œ ë†’ì€ ë ˆë²„ë¦¬ì§€ë¥¼ ê°€ì§„ê²ƒìœ¼ë¡œ ë³¼ ìˆ˜ ìˆë‹¤.
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/f0f2d900-3530-4d99-9fa2-052690c52767/Untitled.png)
    
- ë˜ë‹¤ë¥¸ ì¸¡ì • ì§€í‘œëŠ” ì¿¡ì˜ ê±°ë¦¬ì´ë‹¤. ì´ê²ƒì€ ë ˆë²„ë¦¬ì§€ì™€ í‘œì¤€í™” ì”ì°¨ì˜ í¬ê¸°ë¥¼ í•©ì³ì„œ ì˜í–¥ë ¥ì„ íŒë‹¨í•œë‹¤. ì¿¡ì˜ ê±°ë¦¬ê°€ 4/(n-P-1)ë³´ë‹¤ í¬ë©´ ì˜í–¥ë ¥ì´ ë†’ë‹¤ê³  ë³´ëŠ” í¸ì´ë‹¤.
    - ì˜í–¥ë ¥ê·¸ë¦¼(ê±°í’ˆê·¸ë¦¼)ì€ í‘œì¤€í™” ì”ì°¨, í–‡ê°’(ë ˆë²„ë¦¬ì§€), ì¿¡ì˜ ê±°ë¦¬ë¥¼ ëª¨ë‘ í•œ ê·¸ë¦¼ì— í‘œí˜„í•œë‹¤.
    
    ```python
    influence = OLSInfluence(result_98105)
    fig, ax = plt.subplots(figsize=(5, 5))
    ax.axhline(-2.5, linestyle='--', color='C1')
    ax.axhline(2.5, linestyle='--', color='C1')
    ax.scatter(influence.hat_matrix_diag, influence.resid_studentized_internal, 
               s=1000 * np.sqrt(influence.cooks_distance[0]),
               alpha=0.5)
    
    ax.set_xlabel('hat values')
    ax.set_ylabel('studentized residuals')
    
    plt.tight_layout()
    plt.show()
    
    ```
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/9c05209a-abe6-4656-b638-6443705892ab/Untitled.png)
    
    - íšŒê·€ì—ì„œ ëª‡ëª‡ë°ì´í„°ê°€ í° ì˜í–¥ë ¥ì„ ë³´ì„ì„ ì•Œ ìˆ˜ ìˆë‹¤. ì¿¡ì˜ ê±°ë¦¬ê°€ 0.08ë³´ë‹¤ í° ì ì€ íšŒìƒ‰ìœ¼ë¡œ ê°•ì¡°í•˜ì—¬ í‘œì‹œí•œë‹¤.
    
- í‘œ [4-2]ëŠ” ì „ì²´ë°ì´í„°ë¥¼ ëª¨ë‘ ì‚¬ìš©í–ˆì„ ë•Œì˜ íšŒê·€ ê²°ê³¼ì™€ ê°€ì¥ ì˜í–¥ë ¥ì´ í° ë°ì´í„°ë“¤(ì¿¡ì˜ê±°ë¦¬>0.08)ì„ ì œì™¸í•˜ê³  ì–»ì€ íšŒê·€ê²°ê³¼ë¥¼ ë¹„êµí•œë‹¤.
    - bathroomì˜ íšŒê·€ê³„ìˆ˜ê°€ ì—„ì²­ë‚˜ê²Œ ë³€í•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.
    
    ```python
    mask = [dist < .08 for dist in influence.cooks_distance[0]]
    house_infl = house_98105.loc[mask]
    
    ols_infl = sm.OLS(house_infl[outcome], house_infl[predictors].assign(const=1))
    result_infl = ols_infl.fit()
    
    pd.DataFrame({
        'Original': result_98105.params,
        'Influential removed': result_infl.params,
    })
    
    //ê²°ê³¼
                 Original	   Influential removed
    SqFtTotLiving	209.602346  	  230.052569
    SqFtLot       38.933315   	  33.141600
    Bathrooms   	2282.264145   	-16131.879785
    Bedrooms     -26320.268796  	-22887.865318
    BldgGrade   	130000.099737	  114870.559737
    const      	-772549.862447  	-647137.096716
    
    ```
    

## 4.6.3 ì´ë¶„ì‚°ì„±, ë¹„ì •ê·œì„±, ì˜¤ì°¨ ê´€ ìƒê´€

â€” ì˜¤ì°¨(ëª¨ì§‘ë‹¨)ëŠ” ì§ì ‘ ì•Œì•„ë‚¼ ìˆ˜ ì—†ê¸°ë•Œë¬¸ì— ì”ì°¨(í‘œë³¸ì§‘ë‹¨)ì˜ ë¶„í¬ë¥¼ í†µí•´ ì˜¤ì°¨ë¥¼ ì¶”ì¸¡í•¨. ì¦‰ ì”ì°¨ì˜ ë¶„í¬ê°€ ì˜¤ì°¨ì˜ ë¶„í¬ì´ê³  ì˜¤ì°¨ì˜ ë¶„í¬ê°€ ì•„ë˜ì˜ ì„¸ê°€ì§€ ê°€ì •ì— ì„±ë¦½í•´ì•¼ OLSë¥¼ ì“¸ ìˆ˜ ìˆìŒ.

- ë³´í†µìµœì†Œì œê³±ì¶”ì •(OLS)ë‹¤ì–‘í•œ ë¶„í¬ ê°€ì •í•˜ì—ì„œ í¸í–¥ì„±ë„ ì—†ê³  ê²½ìš°ì— ë”°ë¼ â€˜ìµœì â€™ì´ë¼ê³  í•  ìˆ˜ ìˆëŠ” ì¶”ì •ì„ ì œê³µí•œë‹¤.
- ì”ì°¨ì˜ ë¶„í¬ëŠ” ì£¼ë¡œ ê³µì‹ì ì¸ í†µê³„ì  ì¶”ë¡ (ê°€ì„¤ê²€ì • ë° pê°’)ì˜ ìœ íš¨ì„±ê³¼ ê´€ë ¨ì´ ìˆë‹¤.
    - ì˜¤ì°¨ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤ëŠ” ê²ƒì€ ëª¨ë¸ì´ ì™„ì „í•˜ë‹¤ëŠ” ì‹ í˜¸ë‹¤.
    - ì˜¤ì°¨ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¥´ì§€ ì•ŠëŠ”ë‹¤ëŠ”ê²ƒì€ ëª¨ë¸ì—ì„œ ë­”ê°€ ëˆ„ë½ë˜ì—ˆì„ ìˆ˜ ìˆë‹¤ëŠ”ê²ƒì´ë‹¤.
    - í˜•ì‹ì  ì¶”ë¡ ì´ ì™„ì „íˆ ìœ íš¨í•˜ë ¤ë©´ ì”ì°¨ëŠ”
        - 1.ë™ì¼í•œ ë¶„ì‚°ì„ ê°€ì§€ë©° : ë“±ë¶„ì‚°
        - 2.ì •ê·œë¶„í¬ë¥¼ ê°€ì§€ê³  : ì •ê·œì„±
        - 3.ì„œë¡œ ë…ë¦½ì´ë¼ëŠ” ê°€ì • : ë…ë¦½ì„± ì´ í•„ìš”í•˜ë‹¤.
        
- 3ê°€ì§€ ê°€ì • ì¤‘ ë¨¼ì € 1ë²ˆì˜ ë°˜ëŒ€ì¸ ì´ë¶„ì‚°ì„±ì€ ë‹¤ì–‘í•œ ë²”ìœ„ì˜ ì˜ˆì¸¡ê°’ì— ë”°ë¼ ì”ì°¨ì˜ ë¶„ì‚°ì´ ì¼ì •í•˜ì§€ ì•Šì€ ê²ƒì„ ì˜ë¯¸í•œë‹¤. ì–´ë–¤ ì¼ë¶€ë¶„ì˜ ì˜¤ì°¨ê°€ ë‹¤ë¥¸ë°ë³´ë‹¤ í›¨ì”¬ í¬ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ê²ƒì„ ë§í•œë‹¤.
    
    ```python
    fig, ax = plt.subplots(figsize=(5, 5))
    sns.regplot(x=result_98105.fittedvalues, y=np.abs(result_98105.resid), 
                scatter_kws={'alpha': 0.25},
                line_kws={'color': 'C1'},
                lowess=True, ax=ax)
    ax.set_xlabel('predicted')
    ax.set_ylabel('abs(residual)')
    
    plt.tight_layout()
    plt.show()
    ```
    
    - íšŒê·€ëª¨ë¸ lm_98105ì—ì„œ ì ˆëŒ€ì”ì°¨(ì”ì°¨ì— ì ˆëŒ“ê°’ì”Œì›€)ì™€ ì˜ˆì¸¡ê°’ì˜ ê´€ê³„ë¥¼ ë„ì‹í™”í•œ ê²ƒì´ë‹¤.
        - ì”ì°¨ì˜ ë¶„ì‚°ì€ ê³ ê°€ì˜ ì£¼íƒì¼ ìˆ˜ ë¡ ì¦ê°€í•˜ëŠ” ê²½í–¥ì´ ë³´ì¸ë‹¤.
        - ì´ë¥¼í†µí•´ íšŒê·€ëª¨í˜•ì´ ì´ë¶„ì‚°ì„± ì˜¤ì°¨ë¥¼ ê°€ì§€ê³  ìˆë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤.
            - ì´ë¶„ì‚°ì„±ì€ ì˜ˆì¸¡ê°’ì´ ì–´ë–¤ê²½ìš°ì—ëŠ” ë§ê³  ì–´ë–¤ê²½ìš°ì—ëŠ” í‹€ë¦¬ë‹¤ëŠ”ê²ƒì„ ë‚˜íƒ€ëƒ„. ì–»ì€ ëª¨ë¸ì´ ë¶ˆì™„ì „í•˜ë‹¤ëŠ” ê²ƒì„ ì•Œë ¤ì¤€ë‹¤. ì˜ˆë¥¼ë“¤ë©´ ì•„ë˜ì˜ ì´ë¯¸ì§€ëŠ” íšŒê·€ëª¨í˜•ì´ ê°€ê²©ì´ ë†’ì€ ì£¼íƒì— ëŒ€í•´ì„œëŠ” ì˜ ì„¤ëª…í•˜ì§€ ëª»í•œë‹¤ëŠ” ê²ƒì„ ì•Œë ¤ì¤€ë‹¤.
        
        ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/aaf036d7-3e2e-4ff8-a492-d1df1c935ffc/Untitled.png)
        
- ë‘ë²ˆì§¸ë¡œ ì •ê·œì„±ì„ íˆìŠ¤í† ê·¸ë¨ì„ í†µí•´ ì•Œì•„ë³¼ ìˆ˜ ìˆë‹¤.
    - ì •ê·œë¶„í¬ë³´ë‹¤ ë” ê¼¬ë¦¬ê°€ ê¸¸ê³ , ë” í° ì”ì°¨ì— ì™œê³¡ì´ ìˆë‹¤.
    
    ```python
    **fig, ax = plt.subplots(figsize=(4, 4))
    pd.Series(influence.resid_studentized_internal).hist(ax=ax)
    ax.set_xlabel('std. residual')
    ax.set_ylabel('Frequency')
    
    plt.tight_layout()
    plt.show()**
    ```
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/8dafbb73-c5ab-4072-b9a1-422055afe9c1/Untitled.png)
    
- ë§ˆì§€ë§‰ìœ¼ë¡œ ì˜¤ì°¨ê°€ ë…ë¦½ì ì´ë¼ëŠ” ê°€ì •ì„ ì ê²€í•œë‹¤.
    - íŠ¹íˆ ì‹œê³„ì—´ë°ì´í„°ëŠ” ìê¸°ìƒê´€ì´ ìˆì„ í™•ë¥ ì´ í¬ê¸°ë•Œë¬¸ì— ë”ë¹ˆ-ì™“ìŠ¨ í†µê³„ëŸ‰ì„ ì‚¬ìš©í•´ ìê¸°ìƒê´€ì„ íƒì§€í•œë‹¤.
    - ë§Œì•½ íšŒê·€ëª¨í˜• ì˜¤ì°¨ë“¤ê°„ì— ìƒê´€ê´€ê³„ê°€ ìˆëŠ” ê²½ìš°, ì´ ì •ë³´ëŠ” ë‹¨ê¸°ì˜ˆì¸¡ì— ìœ ìš©í•  ìˆ˜ ìˆê³ , ëª¨ë¸ì„ ë§Œë“¤ë•Œ í•¨ê»˜ ê³ ë ¤í•´ì•¼í•œë‹¤.
    - ì¥ê¸°ì ì˜ˆì¸¡ì´ë‚˜ ì„¤ëª…ëª¨ë¸ì´ í•„ìš”í•  ê²½ìš°ì—ëŠ” ê³¼ë„í•œ ìê¸°ìƒê´€ë°ì´í„°ëŠ” ì‚¬ìš©í•  ìˆ˜ ì—†ë‹¤.
- ì‚°ì ë„ í‰í™œê¸° : ì¼ë ¨ì˜ êµ¬ê°„ë³„ ì§€ì—­íšŒê·€ëª¨í˜•ì„ êµ¬í•œ í›„ ê·¸ê²ƒë“¤ì„ ì—°ì†ì ìœ¼ë¡œ ë¶€ë“œëŸ½ê²Œ ë§Œë“¤ì–´ë‚¸ë‹¤. ì´ë¥¼ í‰í™œí™”ë¼ê³  ë¶€ë¥¸ë‹¤.

## 4.6.4 í¸ì”ì°¨ ê·¸ë¦¼ê³¼ ë¹„ì„ í˜•ì„±

- í¸ì”ì°¨ ê·¸ë¦¼ì€ ì˜ˆì¸¡ ëª¨ë¸ì´ ì˜ˆì¸¡ ë³€ìˆ˜ì™€ ê²°ê³¼ ë³€ìˆ˜ê°„ì˜ ê´€ê³„ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ì„¤ëª…í•˜ëŠ”ì§€ ì‹œê°í™” í•˜ëŠ” ë°©ë²•ì´ë‹¤.
    - í¸ì”ì°¨ ê·¸ë¦¼ì˜ ê¸°ë³¸ê°œë…ì€ í•˜ë‚˜ì˜ ì˜ˆì¸¡ë³€ìˆ˜ì™€ ì‘ë‹µë³€ìˆ˜ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ ëª¨ë“  ë‹¤ë¥¸ ì˜ˆì¸¡ë³€ìˆ˜ë¡œ ë¶€í„° ë¶„ë¦¬í•˜ëŠ” ê²ƒì´ë‹¤.
    - í¸ì”ì°¨ëŠ” ë‹¨ì¼ ì˜ˆì¸¡ ë³€ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì˜ˆì¸¡ê°’ê³¼ ì „ì²´ë¥¼ ê³ ë ¤í•œ íšŒê·€ì‹ì˜ ì‹¤ì œì”ì°¨ë¥¼ ê²°í•©í•˜ì—¬ ë§Œë“  ê²°ê³¼ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤.
    - (Xiì˜ í¸ì”ì°¨) = (íšŒê·€ì‹ì˜ ì‹¤ì œ ì”ì°¨) + ( íšŒê·€í•­)bi-hat *Xi
    - í¸ì”ì°¨ ê·¸ë¦¼ì€ xì¶•ì€ ì˜ˆì¸¡ë³€ìˆ˜, yì¶•ì€ í¸ì”ì°¨ë¥¼ ì˜ë¯¸í•œë‹¤
        - íŒŒì´ì¬ì˜ ê·¸ë¦¼ì—ì„œëŠ” ë³´ì´ì§€ ì•Šì§€ë§Œ ì±…ì˜ ê·¸ë˜í”„ë¥¼ ë³´ë©´ SqFtTotLivingì™€ ì£¼íƒê°€ê²©ì˜ ê´€ê³„ê°€ ë¹„ì„ í˜•ì„ì„ ì•Œ ìˆ˜ ìˆë‹¤. ì‹¤ì„ (íšŒê·€ì„ )ì€ 1000ì œê³±í”¼íŠ¸ë³´ë‹¤ ì‘ì€ í‰ìˆ˜ì˜ ì§‘ì€ ê°€ê²©ì„ ì›ë˜ë³´ë‹¤ ë‚®ê²Œ ì¶”ì •í•˜ê³ , 2000-3000ì œê³±í”¼íŠ¸ ì§‘ì— ëŒ€í•´ì„œëŠ” ë” ë†’ê²Œ ì¶”ì •í•˜ê³  ìˆë‹¤.
        - ì´ëŸ¬í•œ ë¹„ì„ í˜•ì„±ì„ í†µí•´, SqFtTotLivingì— ëŒ€í•´ ë¹„ì„ í˜• í•­ì„ ê³ ë ¤í•  ê²ƒì„ ìƒê°í•´ ë³¼ ìˆ˜ ìˆë‹¤.
    
    ```python
    fig, ax = plt.subplots(figsize=(5, 5))
    fig = sm.graphics.plot_ccpr(result_98105, 'SqFtTotLiving', ax=ax)
    
    plt.tight_layout()
    plt.show()
    ```
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6c999892-c73c-42e9-ac84-2ae267659d7e/Untitled.png)
    

## 4.7 ë‹¤í•­íšŒê·€ì™€ ìŠ¤í”Œë¼ì¸ íšŒê·€

- ì‘ë‹µë³€ìˆ˜ì™€ ì˜ˆì¸¡ë³€ìˆ˜ê°„ì˜ ê´€ê³„ê°€ ë°˜ë“œì‹œ ì„ í˜•ì¼ í•„ìš”ëŠ” ì—†ë‹¤.
    - ì˜ˆë¥¼ë“¤ë©´ ì•½ë¬¼ì˜ ë³µìš©ëŸ‰ì— ë”°ë¥¸ ë°˜ì‘ì€ 2ë°°ë¥¼ ëŠ˜ë¦°ë‹¤ê³  ë°˜ì‘ì´ 2ë°°ë¡œ ëŠ˜ì§€ ì•ŠëŠ”ë‹¤.

<aside>
ğŸ’¡ ìš©ì–´ì •ë¦¬
1. ë‹¤í•­íšŒê·€ : íšŒê·€ëª¨í˜•ì— ë‹¤í•­ì‹(ì œê³±, ì„¸ì œê³± ë“±) í•­ì„ ì¶”ê°€í•œ ë°©ì‹
2. ìŠ¤í”Œë¼ì¸ íšŒê·€ : ë‹¤í•­ êµ¬ê°„ë“¤ì„ ë¶€ë“œëŸ¬ìš´ ê³¡ì„  í˜•íƒœë¡œ í”¼íŒ…í•œë‹¤.
3. ë§¤ë“­ : ìŠ¤í”Œë¼ì¸ êµ¬ê°„ì„ êµ¬ë¶„í•˜ëŠ” ê°’ë“¤
4. ì¼ë°˜í™” ê°€ë²•ëª¨í˜• (GAM) : ìë™ìœ¼ë¡œ êµ¬ê°„ì„ ê²°ì •í•˜ëŠ” ìŠ¤í”Œë¼ì¸ ëª¨ë¸

</aside>

- ë¹„ì„ í˜• íšŒê·€ : ìµœì†Œì œê³±ë°©ë²•(OLS)ë¥¼ ë°©ë²•ìœ¼ë¡œ í”¼íŒ…í•  ìˆ˜ ì—†ëŠ” ëª¨ë¸ì„ ì˜ë¯¸í•œë‹¤. ë³¸ì§ˆì ìœ¼ë¡œ ì˜ˆì¸¡ë³€ìˆ˜ë“¤ì˜ ì„ í˜•ê²°í•© ë˜ëŠ” ì¼ë¶€ ë³€í™˜ìœ¼ë¡œ ì‘ë‹µë³€ìˆ˜ë¥¼ í‘œí˜„ í•  ìˆ˜ ì—†ëŠ” ëª¨ë“  ëª¨ë¸ì„ ë§í•œë‹¤. ë¹„ì„ í˜•íšŒê·€ëª¨í˜•ì€ ìˆ˜ì¹˜ ìµœì í™”ê°€ í•„ìš”í•˜ê¸° ë•Œë¬¸ì— í”¼íŒ…í•˜ê¸°ê°€ ì–´ë µê³ , ë” ë§ì€ ê³„ì‚°ì„ í•„ìš”ë¡œ í•œë‹¤. ì´ëŸ¬í•œ ì´ìœ ë¡œ ê°€ëŠ¥í•˜ë©´ ì„ í˜•ëª¨í˜•ì„ ì´ìš©í•œë‹¤.

## 4.7.1 ë‹¤í•­ì‹

- ë‹¤í•­íšŒê·€ë€ íšŒê·€ì‹ì— ë‹¤í•­ í•­ì„ í¬í•¨í•œ ê²ƒì„ ë§í•œë‹¤. 
ì˜ˆë¥¼ ë“¤ë©´ ì‘ë‹µë³€ìˆ˜ Yì™€ ì˜ˆì¸¡ë³€ìˆ˜ Xê°„ì˜ ì´ì°¨ íšŒê·€ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì‹ìœ¼ë¡œ í‘œí˜„ í•  ìˆ˜ ìˆë‹¤.
Y= b0+b1*X + b2*X^2 + e
- ë‹¤ìŒì€ í‚¹ì¹´ìš´í‹° ì£¼íƒì˜ˆì œë¡œ êµ¬í•œ SqFtTotLivingì— ëŒ€í•´ ì´ì°¨ ë‹¤í•­ì‹ì„ í”¼íŒ…í•˜ëŠ” ê³¼ì •ì„ ë³´ì—¬ì¤€ë‹¤.
    - ë‹¤í•­íšŒê·€ëŠ” polyí•¨ìˆ˜ë¥¼ ì´ìš©í•´ êµ¬í•  ìˆ˜ ìˆë‹¤.
    
    ```python
    model_poly = smf.ols(formula='AdjSalePrice ~  SqFtTotLiving + np.power(SqFtTotLiving, 2) + ' + 
                    'SqFtLot + Bathrooms + Bedrooms + BldgGrade', data=house_98105)
    result_poly = model_poly.fit()
    print(result_poly.summary())
    
    //ê²°ê³¼
    OLS Regression Results                            
    ==============================================================================
    Dep. Variable:           AdjSalePrice   R-squared:                       0.806
    Model:                            OLS   Adj. R-squared:                  0.802
    Method:                 Least Squares   F-statistic:                     211.6
    Date:                Sun, 31 Jul 2022   Prob (F-statistic):          9.95e-106
    Time:                        17:15:22   Log-Likelihood:                -4217.9
    No. Observations:                 313   AIC:                             8450.
    Df Residuals:                     306   BIC:                             8476.
    Df Model:                           6                                         
    Covariance Type:            nonrobust                                         
    ==============================================================================================
                                     coef    std err          t      P>|t|      [0.025      0.975]
    ----------------------------------------------------------------------------------------------
    Intercept                  -6.159e+05   1.03e+05     -5.953      0.000   -8.19e+05   -4.12e+05
    SqFtTotLiving                  7.4521     55.418      0.134      0.893    -101.597     116.501
    np.power(SqFtTotLiving, 2)     0.0388      0.010      4.040      0.000       0.020       0.058
    SqFtLot                       32.5594      5.436      5.990      0.000      21.863      43.256
    Bathrooms                  -1435.1231   1.95e+04     -0.074      0.941   -3.99e+04     3.7e+04
    Bedrooms                   -9191.9441   1.33e+04     -0.693      0.489   -3.53e+04    1.69e+04
    BldgGrade                   1.357e+05   1.49e+04      9.087      0.000    1.06e+05    1.65e+05
    ==============================================================================
    Omnibus:                       75.161   Durbin-Watson:                   1.625
    Prob(Omnibus):                  0.000   Jarque-Bera (JB):              637.978
    Skew:                           0.699   Prob(JB):                    2.92e-139
    Kurtosis:                       9.853   Cond. No.                     7.37e+07
    ==============================================================================
    
    Notes:
    [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
    [2] The condition number is large, 7.37e+07. This might indicate that there are
    strong multicollinearity or other numerical problems.
    ```
    
    - ê²°ê³¼ë¥¼ í†µí•´ SqFtTotLiving ì— ëŒ€í•œ ë‘ ê°€ì§€ ê³„ìˆ˜ê°€ ìˆëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. í•˜ë‚˜ëŠ” ì¼ì°¨í•­ì´ê³  í•˜ë‚˜ëŠ” ì´ì°¨í•­ì´ë‹¤.
    
    ```python
    def partialResidualPlot(model, df, outcome, feature, ax):
        y_pred = model.predict(df)
        copy_df = df.copy()
        for c in copy_df.columns:
            if c == feature:
                continue
            copy_df[c] = 0.0
        feature_prediction = model.predict(copy_df)
        results = pd.DataFrame({
            'feature': df[feature],
            'residual': df[outcome] - y_pred,
            'ypartial': feature_prediction - model.params[0],
        })
        results = results.sort_values(by=['feature'])
        smoothed = sm.nonparametric.lowess(results.ypartial, results.feature, frac=1/3)
        
        ax.scatter(results.feature, results.ypartial + results.residual)
        ax.plot(smoothed[:, 0], smoothed[:, 1], color='gray')
        ax.plot(results.feature, results.ypartial, color='black')
        ax.set_xlabel(feature)
        ax.set_ylabel(f'Residual + {feature} contribution')
        return ax
    
    fig, ax = plt.subplots(figsize=(5, 5))
    partialResidualPlot(result_poly, house_98105, 'AdjSalePrice', 'SqFtTotLiving', ax)
    
    plt.tight_layout()
    plt.show()
    print(result_poly.params[2])
    ```
    
    - ë³€ìˆ˜ì— ëŒ€í•œ ë‹¤í•­íšŒê·€ ê²°ê³¼ (ì§„í•œ ì„ ), í‰í™œê³¡ì„ (ì—°í•œì„ )
        - ì„ í˜•íšŒê·€ì¼ë•Œë³´ë‹¤ í‰í™œê³¡ì„ ì— ë” ê°€ê¹Œì›Œì§
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/1559b0d0-b5cc-48db-b9b4-32cb41c42430/Untitled.png)
    

## 4.7.2 ìŠ¤í”Œë¼ì¸

- ë‹¤í•­íšŒê·€ëŠ” ë¹„ì„ í˜•ê´€ê³„ì— ëŒ€í•´ ì–´ëŠì •ë„ ê³¡ë¥ ì„ ë‹´ì•„ë‚¼ ìˆ˜ ìˆì§€ë§Œ, ê³ ì°¨í•­ì´ ì¶”ê°€ë˜ë©´ í”ë“¤ë¦¼ì„ ì´ˆë˜í•  ìˆ˜ ìˆë‹¤.
- ë” ë‚˜ì€ ë°©ì‹ì€ ìŠ¤í”Œë¼ì¸ì„ ì‚¬ìš©í•˜ëŠ”ê²ƒì´ë‹¤.
ìŠ¤í”Œë¼ì¸ì´ë€ ê³ ì •ëœ ì ë“¤ ì‚¬ì´ë¥¼ ë¶€ë“œëŸ½ê²Œ ë³´ê°„í•˜ëŠ” ë°©ë²•ì„ ë§í•œë‹¤. 
ìŠ¤í”Œë¼ì¸ì— ëŒ€í•œ ì¢€ ë” ê¸°ìˆ ì ì¸ ì •ì˜ëŠ” ì¡°ê°ë³„ ì—°ì† ë‹¤í•­ì‹ì´ë‹¤.
    - êµ¬ê°„ë³„ ë‹¤í•­ì‹ì€ ì˜ˆì¸¡ë³€ìˆ˜ë¥¼ ìœ„í•œ ì¼ë ¨ì˜ ê³ ì •ëœ ì (ë§¤ë“­) ì‚¬ì´ë¥¼ ë¶€ë“œëŸ½ê²Œ ì—°ê²°í•œë‹¤. ìŠ¤í”Œë¼ì¸ì„ êµ¬í•˜ëŠ”ê²ƒì€ ë‹¤í•­íšŒê·€ë³´ë‹¤ í›¨ì”¬ ë³µì¡í•˜ë‹¤.
    - ì´ë¥¼ ìœ„í•´ì„œëŠ” ë‹¤í•­ì‹ì˜ ì°¨ìˆ˜ì™€ ë§¤ë“­ì˜ ìœ„ì¹˜ë¼ëŠ” íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•˜ë‹¤.
    - statsmodelsì˜ formulaì¸í„°í˜ì´ìŠ¤ëŠ” ììœ ë„dfë¥¼ì‚¬ìš©í•˜ì—¬ b-ìŠ¤í”Œë¼ì¸(ê¸°ë³¸ ìŠ¤í”Œë¼ì¸)ì„ ì§€ì •í•œë‹¤. ì´ë ‡ê²Œ í•˜ë©´ df - degree(ì°¨ìˆ˜) = 6-3 = 3ê°œì˜ ë‚´ë¶€ ë§¤ë“­ì´ ìƒì„±ëœë‹¤.
    
    ```python
    formula = ('AdjSalePrice ~ bs(SqFtTotLiving, df=6, degree=3) + ' + 
               'SqFtLot + Bathrooms + Bedrooms + BldgGrade')
    model_spline = smf.ols(formula=formula, data=house_98105)
    result_spline = model_spline.fit()
    print(result_spline.summary())
    
    //ê²°ê³¼ 
    OLS Regression Results                            
    ==============================================================================
    Dep. Variable:           AdjSalePrice   R-squared:                       0.814
    Model:                            OLS   Adj. R-squared:                  0.807
    Method:                 Least Squares   F-statistic:                     131.8
    Date:                Sun, 31 Jul 2022   Prob (F-statistic):          7.10e-104
    Time:                        17:31:33   Log-Likelihood:                -4211.4
    No. Observations:                 313   AIC:                             8445.
    Df Residuals:                     302   BIC:                             8486.
    Df Model:                          10                                         
    Covariance Type:            nonrobust                                         
    ========================================================================================================
                                               coef    std err          t      P>|t|      [0.025      0.975]
    --------------------------------------------------------------------------------------------------------
    Intercept                            -4.142e+05   1.43e+05     -2.899      0.004   -6.95e+05   -1.33e+05
    bs(SqFtTotLiving, df=6, degree=3)[0] -1.995e+05   1.86e+05     -1.076      0.283   -5.65e+05    1.66e+05
    bs(SqFtTotLiving, df=6, degree=3)[1] -1.206e+05   1.23e+05     -0.983      0.326   -3.62e+05    1.21e+05
    bs(SqFtTotLiving, df=6, degree=3)[2] -7.164e+04   1.36e+05     -0.525      0.600    -3.4e+05    1.97e+05
    bs(SqFtTotLiving, df=6, degree=3)[3]  1.957e+05   1.62e+05      1.212      0.227   -1.22e+05    5.14e+05
    bs(SqFtTotLiving, df=6, degree=3)[4]  8.452e+05   2.18e+05      3.878      0.000    4.16e+05    1.27e+06
    bs(SqFtTotLiving, df=6, degree=3)[5]  6.955e+05   2.14e+05      3.255      0.001    2.75e+05    1.12e+06
    SqFtLot                                 33.3258      5.454      6.110      0.000      22.592      44.059
    Bathrooms                            -4778.2080   1.94e+04     -0.246      0.806    -4.3e+04    3.34e+04
    Bedrooms                             -5778.7045   1.32e+04     -0.437      0.663   -3.18e+04    2.03e+04
    BldgGrade                             1.345e+05   1.52e+04      8.842      0.000    1.05e+05    1.64e+05
    ==============================================================================
    Omnibus:                       58.816   Durbin-Watson:                   1.633
    Prob(Omnibus):                  0.000   Jarque-Bera (JB):              622.021
    Skew:                           0.330   Prob(JB):                    8.51e-136
    Kurtosis:                       9.874   Cond. No.                     1.97e+05
    ==============================================================================
    
    Notes:
    [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
    [2] The condition number is large, 1.97e+05. This might indicate that there are
    strong multicollinearity or other numerical problems.
    
    ```
    
    - ì„ í˜•í•­ì—ì„œëŠ” ê³„ìˆ˜ê°€ ì§ì ‘ì ì¸ ì˜ë¯¸ë¥¼ ê°–ì§€ë§Œ, ìŠ¤í”Œë¼ì¸ í•­ì˜ ê³„ìˆ˜ëŠ” í•´ì„í•˜ê¸°ê°€ ì–´ë ¤ì›Œ ì‹œê°í™”ë°©ë²•ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” ìœ ìš©í•˜ë‹¤.
    - ë‹¤í•­íšŒê·€ëª¨í˜•ê³¼ ë‹¬ë¦¬ ì¢€ë” ë§¤ë„ëŸ½ê²Œ ë§¤ì¹­ë˜ëŠ”ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.
    
    ```python
    fig, ax = plt.subplots(figsize=(5, 5))
    partialResidualPlot(result_spline, house_98105, 'AdjSalePrice', 'SqFtTotLiving', ax)
    
    plt.tight_layout()
    plt.show()
    ```
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6d85c0f2-4282-4245-85b9-867cd724357e/Untitled.png)
    

## 4.7.3 ì¼ë°˜í™”ê°€ë²•ëª¨í˜•(GAM)

- ë‹¤í•­í•­ì€ ê´€ê³„ë¥¼ í¬ì°©í•˜ê¸°ì— ìœ ì—°ì„±ì´ ë¶€ì¡±í•  ìˆ˜ ìˆìœ¼ë©°, ìŠ¤í”Œë¼ì¸ í•­ì€ ë§¤ë“­ì„ ì–´ë””ë¡œ í• ì§€ ì •í•´ì¤˜ì•¼í•œë‹¤. 
ì¼ë°˜í™”ê°€ë²•ëª¨í˜•ì€ ìŠ¤í”Œë¼ì¸ íšŒê·€ë¥¼ ìë™ìœ¼ë¡œ ì°¾ëŠ”ë° ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìœ ë™ì ì¸ ëª¨ë¸ë§ ê¸°ìˆ ì´ë‹¤.


```python
predictors = ['SqFtTotLiving', 'SqFtLot', 'Bathrooms', 
              'Bedrooms', 'BldgGrade']
outcome = 'AdjSalePrice'
X = house_98105[predictors].values
y = house_98105[outcome]

## model - predictioì˜ ì¸ë±ìŠ¤ì™€ ëª¨í˜•ì„ ì„ íƒí•  ìˆ˜ ìˆë‹¤. s:spline , l:linear, n_spline : ë§¤ë“­ê°œìˆ˜..?
gam = LinearGAM(s(0, n_splines=12) + l(1) + l(2) + l(3) + l(4))
gam.gridsearch(X, y)
print(gam.summary())

//ê²°ê³¼
LinearGAM                                                                                                 
=============================================== ==========================================================
Distribution:                        NormalDist Effective DoF:                                      7.6772
Link Function:                     IdentityLink Log Likelihood:                                 -7833.1159
Number of Samples:                          313 AIC:                                            15683.5863
                                                AICc:                                             15684.14
                                                GCV:                                      30838885095.1677
                                                Scale:                                    29480381715.8292
                                                Pseudo R-Squared:                                   0.8117
==========================================================================================================
Feature Function                  Lambda               Rank         EDoF         P > x        Sig. Code   
================================= ==================== ============ ============ ============ ============
s(0)                              [15.8489]            12           4.3          1.11e-16     ***         
l(1)                              [15.8489]            1            0.9          2.35e-10     ***         
l(2)                              [15.8489]            1            0.8          8.45e-01                 
l(3)                              [15.8489]            1            0.9          3.79e-01                 
l(4)                              [15.8489]            1            0.8          1.11e-16     ***         
intercept                                              1            0.0          9.14e-01                 
==========================================================================================================
Significance codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

WARNING: Fitting splines and a linear function to a feature introduces a model identifiability problem
         which can cause p-values to appear significant when they are not.

WARNING: p-values calculated in this manner behave correctly for un-penalized models or models with
         known smoothing parameters, but when smoothing parameters have been estimated, the p-values
         are typically lower than they should be, meaning that the tests reject the null too readily.

//ê·¸ë˜í”„ ì¶œë ¥
fig, axes = plt.subplots(figsize=(8, 8), ncols=2, nrows=3)

titles = ['SqFtTotLiving', 'SqFtLot', 'Bathrooms', 'Bedrooms', 'BldgGrade']
for i, title in enumerate(titles):
    ax = axes[i // 2, i % 2]
    XX = gam.generate_X_grid(term=i)
    ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX))
    ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX, width=.95)[1], c='r', ls='--')
    ax.set_title(titles[i]);
    
axes[2][1].set_visible(False)

plt.tight_layout()
plt.show()
```
